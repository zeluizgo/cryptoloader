<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
            <name>dfs.namenode.name.dir</name>
            <value>/hadoop_data/dfs/name</value>
    </property>
    <property>
            <name>dfs.datanode.data.dir</name>
            <value>/hadoop_data/dfs/data</value>
    </property>
    <!-- Critical for Raspberry Pi + Docker -->
    <property>
        <name>dfs.datanode.max.transfer.threads</name>
        <value>4096</value>
    </property>
    <!-- Critical stability settings for Docker/Pi clusters -->
    <property>
        <name>dfs.heartbeat.interval</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.heartbeat.recheck-interval</name>
        <value>30000</value>
    </property>
    <property>
        <name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
        <value>NEVER</value>
    </property>
    <property>
        <name>dfs.replication</name><value>3</value>
    </property>
    <property>
        <name>dfs.blocksize</name><value>134217728</value>
    </property> <!-- 128MB -->
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>10</value>
    </property>
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>20</value>
    </property>
    <property>
            <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
            <value>false</value>
    </property>
    <property>
        <name>dfs.datanode.use.datanode.hostname</name>
        <value>true</value>
    </property>

    <property>
        <name>dfs.client.use.datanode.hostname</name>
        <value>true</value>
    </property>

    <property>
        <name>dfs.datanode.hostname</name>
        <value>${HOSTNAME}</value>
    </property>

</configuration>