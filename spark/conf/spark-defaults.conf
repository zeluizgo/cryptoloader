#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# ============================================
# APPLICATION SETTINGS
# ============================================
spark.master                     yarn
spark.app.name                   SpringBootSparkParquet
spark.submit.deployMode          client

# ============================================
# HDFS CONFIGURATION
# ============================================
spark.hadoop.fs.defaultFS                hdfs://spark-master:9000

# ============================================
# HIVE CONFIGURATION
# ============================================
spark.sql.catalogImplementation          in-memory
#spark.hadoop.hive.metastore.uris         thrift://hive-server:9083
#spark.sql.warehouse.dir                  hdfs://spark-master:9000/datasets
#spark.hadoop.hive.conf.dir               /tmp/hive-conf

# ============================================
# YARN CONFIGURATION
# ============================================
spark.yarn.jars                          hdfs://spark-master:9000/shared-libs/*
spark.yarn.am.memory                     256m
spark.yarn.submit.waitAppCompletion      false

# ============================================
# EVENT LOG & HISTORY
# ============================================
spark.eventLog.enabled            true
spark.eventLog.dir                hdfs://spark-master:9000/spark-logs

spark.history.provider            org.apache.spark.deploy.history.FsHistoryProvider
spark.history.fs.logDirectory     hdfs://spark-master:9000/spark-logs
spark.history.fs.update.interval  10s
spark.history.ui.port             18080

# ============================================
# SERIALIZATION
# ============================================

# FINAL KRYO CONFIG — THE ONE THAT WORKS
spark.serializer                        org.apache.spark.serializer.KryoSerializer
spark.kryo.unsafe                       false
spark.kryo.referenceTracking            false
spark.kryo.registrationRequired         false
spark.kryo.registrator                  com.example.udf.MyKryoRegistrator
#spark.kryo.classesToRegister      com.example.service.IndicatorsService$CalcDivisionUDF,com.example.service.IndicatorsService$CalcGainUDF,com.example.service.IndicatorsService$CalcLossUDF,com.example.service.IndicatorsService$CalcRSIUDF,com.example.service.IndicatorsService$CalcStochasticKUDF,com.example.service.IndicatorsService$CalcBBandLowerUDF,com.example.service.IndicatorsService$CalcBBandUpperUDF

# ============================================
# JAVA 17 COMPATIBILITY
# ============================================
# THESE 4 LINES ARE THE MAGIC — NEVER REMOVE ANY
# THESE 5 LINES ARE NON-NEGOTIABLE — MISSING ANY = DEATH
spark.driver.extraJavaOptions          \
    --add-opens=java.base/java.lang.invoke=ALL-UNNAMED \
    --add-opens=java.base/java.util=ALL-UNNAMED \
    --add-opens=java.base/java.nio=ALL-UNNAMED \
    --add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
    --add-opens=java.base/java.lang=ALL-UNNAMED

spark.executor.extraJavaOptions        \
    --add-opens=java.base/java.lang.invoke=ALL-UNNAMED \
    --add-opens=java.base/java.util=ALL-UNNAMED \
    --add-opens=java.base/java.nio=ALL-UNNAMED \
    --add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
    --add-opens=java.base/java.lang=ALL-UNNAMED


# Optional but clean
spark.ui.enabled                        false        # removes the ConcurrentModificationException bug
spark.sql.adaptive.enabled              false


# ============================================
# MEMORY CONFIGURATION
# ============================================
spark.driver.memory              512m
spark.executor.memory            512m
spark.executor.cores             2
spark.executor.instances         2

# ============================================
# LOCAL DIRECTORIES
# ============================================
#spark.local.dir                          /tmp/spark-local